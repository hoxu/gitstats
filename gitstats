#!/usr/bin/env python3
# Copyright (c) 2007-2014 Heikki Hokkanen <hoxu@users.sf.net> & others (see doc/AUTHOR)
# GPLv2 / GPLv3
import datetime
import getopt
import glob
import json
import os
import pickle
import platform
import re
import shutil
import subprocess
import sys
import time
import zlib
import multiprocessing

from multiprocessing import Pool

import html

os.environ['LC_ALL'] = 'C'

ON_LINUX = (platform.system() == 'Linux')
WEEKDAYS = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')
JSONFILE = 'gitstats.json'

exectime_internal = 0.0
exectime_external = 0.0
time_start = time.time()

conf = {
	'max_domains': 10,
	'max_ext_length': 10,
	'style': 'gitstats.css',
	'max_authors': 20,
	'authors_top': 5,
	'commit_begin': '',
	'commit_end': 'HEAD',
	'linear_linestats': 1,
	'project_name': '',
	'processes': multiprocessing.cpu_count(),
	'start_date': '',
	'end_date': '',
	'excluded_authors': [],
	'excluded_prefixes': []
}

def getpipeoutput(cmds, quiet = False):
	global exectime_external
	start = time.time()
	if not quiet and ON_LINUX and os.isatty(1):
		print('>> ' + ' | '.join(cmds))
		sys.stdout.flush()
	p = subprocess.Popen(cmds[0], stdout = subprocess.PIPE, shell = True)
	processes=[p]
	for x in cmds[1:]:
		p = subprocess.Popen(x, stdin = p.stdout, stdout = subprocess.PIPE, shell = True)
		processes.append(p)
	output = (p.communicate()[0]).decode("utf-8")
	for p in processes:
		p.wait()
	end = time.time()
	if not quiet:
		if ON_LINUX and os.isatty(1):
			print('\r')
		print('[%.5f] >> %s' % (end - start, ' | '.join(cmds)))
	exectime_external += (end - start)
	return output.rstrip('\n')

def getlogrange(defaultrange = 'HEAD', end_only = True):
	commit_range = getcommitrange(defaultrange, end_only)
	datesel = ''
	if len(conf['start_date']) > 0:
		datesel = '--since="%s" %s' % (conf['start_date'], datesel)
	if len(conf['end_date']) > 0:
		datesel = '--until="%s" %s' % (conf['end_date'], datesel)
    
	if (len(datesel) > 0):
		commit_range = '%s "%s"' % (datesel, commit_range)

	return commit_range

def getcommitrange(defaultrange = 'HEAD', end_only = False):
	if len(conf['commit_end']) > 0:
		if end_only or len(conf['commit_begin']) == 0:
			return conf['commit_end']
		return '%s..%s' % (conf['commit_begin'], conf['commit_end'])
	return defaultrange

def getkeyssortedbyvalues(dict):
	return [el[1] for el in sorted([(el[1], el[0]) for el in list(dict.items())])]

# dict['author'] = { 'commits': 512 } - ...key(dict, 'commits')
def getkeyssortedbyvaluekey(d, key):
	return [el[1] for el in sorted([(d[el][key], el) for el in list(d.keys())])]

def getstatsummarycounts(line):
	numbers = re.findall('\d+', line)
	if   len(numbers) == 1:
		# neither insertions nor deletions: may probably only happen for "0 files changed"
		numbers.append(0);
		numbers.append(0);
	elif len(numbers) == 2 and line.find('(+)') != -1:
		numbers.append(0);    # only insertions were printed on line
	elif len(numbers) == 2 and line.find('(-)') != -1:
		numbers.insert(1, 0); # only deletions were printed on line
	return numbers

VERSION = 0
def getversion():
	global VERSION
	if VERSION == 0:
		gitstats_repo = os.path.dirname(os.path.abspath(__file__))
		VERSION = getpipeoutput(["git --git-dir=%s/.git --work-tree=%s rev-parse --short %s" %
			(gitstats_repo, gitstats_repo, getcommitrange('HEAD').split('\n')[0])])
	return VERSION

def getgitversion():
	return getpipeoutput(['git --version']).split('\n')[0]

def getnumoffilesfromrev(time_rev):
	"""
	Get number of files changed in commit
	"""
	time, rev = time_rev
	return (int(time), rev, int(getpipeoutput(['git ls-tree -r --name-only "%s"' % rev, 'wc -l']).split('\n')[0]))

def getnumoflinesinblob(ext_blob):
	"""
	Get number of lines in blob
	"""
	ext, blob_id = ext_blob
	return (ext, blob_id, int(getpipeoutput(['git cat-file blob %s' % blob_id, 'wc -l']).split()[0]))

class DataCollector:
	"""Manages data collection from a revision control repository."""
	def __init__(self):
		self.stamp_created = time.time()
		self.cache = {}
		self.total_branches = 0
		self.total_tags = 0
		self.total_authors = 0
		self.activity_by_hour_of_day = {} # hour -> commits
		self.activity_by_day_of_week = {} # day -> commits
		self.activity_by_month_of_year = {} # month [1-12] -> commits
		self.activity_by_hour_of_week = {} # weekday -> hour -> commits
		self.activity_by_hour_of_day_busiest = 0
		self.activity_by_hour_of_week_busiest = 0
		self.activity_by_year_week = {} # yy_wNN -> commits
		self.activity_by_year_week_peak = 0
		self.lineactivity_by_hour_of_day = {} # hour -> commits
		self.lineactivity_by_day_of_week = {} # day -> commits
		self.lineactivity_by_month_of_year = {} # month [1-12] -> commits
		self.lineactivity_by_hour_of_week = {} # weekday -> hour -> commits
		self.lineactivity_by_hour_of_day_busiest = 0
		self.lineactivity_by_hour_of_week_busiest = 0
		self.lineactivity_by_year_week = {} # yy_wNN -> commits
		self.lineactivity_by_year_week_peak = 0
		self.changes_by_date_by_author = {} # stamp -> author -> lines_added
		self.changes_by_month_by_author = {} # stamp -> author -> lines_added

		self.authors = {} # name -> {commits, first_commit_stamp, last_commit_stamp, last_active_day, active_days, lines_added, lines_removed}

		self.total_commits = 0
		self.total_files = 0
		self.authors_by_commits = 0

		# domains
		self.domains = {} # domain -> commits

		# author of the month
		self.author_of_month = {} # month -> author -> commits
		self.author_of_year = {} # year -> author -> commits
		self.commits_by_month = {} # month -> commits
		self.commits_by_year = {} # year -> commits
		self.lines_added_by_month = {} # month -> lines added
		self.lines_added_by_year = {} # year -> lines added
		self.lines_removed_by_month = {} # month -> lines removed
		self.lines_removed_by_year = {} # year -> lines removed
		self.first_commit_stamp = 0
		self.last_commit_stamp = 0
		self.last_active_day = None
		self.active_days = set()

		# lines
		self.total_lines = 0
		self.total_lines_added = 0
		self.total_lines_removed = 0

		# size
		self.total_size = 0

		# timezone
		self.commits_by_timezone = {} # timezone -> commits

		# tags
		self.tags = {}

		self.files_by_stamp = {} # stamp -> files
		self.files_by_month = {} # year-month -> files

		# extensions
		self.extensions = {} # extension -> files, lines

		# line statistics
		self.changes_by_date = {} # stamp -> { files, ins, del }
		self.changes_by_month = {} # yy-MM -> { files, ins, del }
		self.changes_by_year = {} # yy -> { files, ins, del }

	##
	# This should be the main function to extract data from the repository.
	def collect(self, dir):
		self.dir = dir
		if len(conf['project_name']) == 0:
			self.projectname = os.path.basename(os.path.abspath(dir))
		else:
			self.projectname = conf['project_name']
	
	##
	# Load cacheable data
	def loadCache(self, cachefile):
		if not os.path.exists(cachefile):
			return
		print('Loading cache...')
		f = open(cachefile, 'rb')
		try:
			self.cache = pickle.loads(zlib.decompress(f.read()))
		except:
			# temporary hack to upgrade non-compressed caches
			f.seek(0)
			self.cache = pickle.load(f)
		f.close()
	
	##
	# Produce any additional statistics from the extracted data.
	def refine(self):
		pass

	##
	# : get a dictionary of author
	def getAuthorInfo(self, author):
		return None
	
	def getActivityByDayOfWeek(self):
		return {}

	def getActivityByHourOfDay(self):
		return {}
	
	def getLineActivityByDayOfWeek(self):
		return {}

	def getLineActivityByHourOfDay(self):
		return {}

	# : get a dictionary of domains
	def getDomainInfo(self, domain):
		return None

	##
	# Get a list of authors
	def getAuthors(self):
		return []
	
	def getFirstCommitDate(self):
		return datetime.datetime.now()
	
	def getLastCommitDate(self):
		return datetime.datetime.now()
	
	def getStampCreated(self):
		return self.stamp_created
	
	def getTags(self):
		return []
	
	def getTotalAuthors(self):
		return -1
	
	def getTotalCommits(self):
		return -1
		
	def getTotalFiles(self):
		return -1
	
	def getTotalLines(self):
		return -1
	
	def getTotalLOC(self):
		return -1
	
	##
	# Save cacheable data
	def saveCache(self, cachefile):
		print('Saving cache...')
		tempfile = cachefile + '.tmp'
		f = open(tempfile, 'wb')
		#pickle.dump(self.cache, f)
		data = zlib.compress(pickle.dumps(self.cache))
		f.write(data)
		f.close()
		try:
			os.remove(cachefile)
		except OSError:
			pass
		os.rename(tempfile, cachefile)

class GitDataCollector(DataCollector):
	def collect(self, dir):
		DataCollector.collect(self, dir)

		self.total_authors += int(getpipeoutput(['git shortlog -s %s' % getlogrange(), 'wc -l']))
		self.total_branches += int(getpipeoutput(['git branch -r', 'wc -l']))
		self.total_tags += int(getpipeoutput(['git tag', 'wc -l']))
		#self.total_lines = int(getoutput('git-ls-files -z |xargs -0 cat |wc -l'))

		# tags
		lines = getpipeoutput(['git show-ref --tags']).split('\n')
		for line in lines:
			if len(line) == 0:
				continue
			(hash, tag) = line.split(' ')

			tag = tag.replace('refs/tags/', '')
			output = getpipeoutput(['git log "%s" --pretty=format:"%%at %%aN" -n 1' % hash])
			if len(output) > 0:
				parts = output.split(' ')
				stamp = 0
				try:
					stamp = int(parts[0])
				except ValueError:
					stamp = 0
				self.tags[tag] = { 'stamp': stamp, 'hash' : hash, 'date' : datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), 'commits': 0, 'authors': {} }

		# collect info on tags, starting from latest
		tags_sorted_by_date_desc = list(map(lambda el : el[1], reversed(sorted(map(lambda el : (el[1]['date'], el[0]), self.tags.items())))))
		prev = None
		for tag in reversed(tags_sorted_by_date_desc):
			cmd = 'git shortlog -s "%s"' % tag
			if prev != None:
				cmd += ' "^%s"' % prev
			output = getpipeoutput([cmd])
			if len(output) == 0:
				continue
			prev = tag
			for line in output.split('\n'):
				parts = re.split('\s+', line, 2)
				commits = int(parts[1])
				author = parts[2]
				if author in conf["excluded_authors"]:
					continue
				self.tags[tag]['commits'] += commits
				self.tags[tag]['authors'][author] = commits

		# Collect revision statistics
		# Outputs "<stamp> <date> <time> <timezone> <author> '<' <mail> '>'"
		lines = getpipeoutput(['git rev-list --pretty=format:"%%at %%ai %%aN <%%aE>" %s' % getlogrange('HEAD'), 'grep -v ^commit']).split('\n')
		for line in lines:
			parts = line.split(' ', 4)
			author = ''
			try:
				stamp = int(parts[0])
			except ValueError:
				stamp = 0
			timezone = parts[3]
			author, mail = parts[4].split('<', 1)
			author = author.rstrip()
			if author in conf["excluded_authors"]:
				continue
			mail = mail.rstrip('>')
			domain = '?'
			if mail.find('@') != -1:
				domain = mail.rsplit('@', 1)[1]
			date = datetime.datetime.fromtimestamp(float(stamp))

			# First and last commit stamp (may be in any order because of cherry-picking and patches)
			if stamp > self.last_commit_stamp:
				self.last_commit_stamp = stamp
			if self.first_commit_stamp == 0 or stamp < self.first_commit_stamp:
				self.first_commit_stamp = stamp

			# activity
			# hour
			hour = date.hour
			self.activity_by_hour_of_day[hour] = self.activity_by_hour_of_day.get(hour, 0) + 1
			# most active hour?
			if self.activity_by_hour_of_day[hour] > self.activity_by_hour_of_day_busiest:
				self.activity_by_hour_of_day_busiest = self.activity_by_hour_of_day[hour]

			# day of week
			day = date.weekday()
			self.activity_by_day_of_week[day] = self.activity_by_day_of_week.get(day, 0) + 1

			# domain stats
			if domain not in self.domains:
				self.domains[domain] = {}
			# commits
			self.domains[domain]['commits'] = self.domains[domain].get('commits', 0) + 1

			# hour of week
			if day not in self.activity_by_hour_of_week:
				self.activity_by_hour_of_week[day] = {}
			self.activity_by_hour_of_week[day][hour] = self.activity_by_hour_of_week[day].get(hour, 0) + 1
			# most active hour?
			if self.activity_by_hour_of_week[day][hour] > self.activity_by_hour_of_week_busiest:
				self.activity_by_hour_of_week_busiest = self.activity_by_hour_of_week[day][hour]

			# month of year
			month = date.month
			self.activity_by_month_of_year[month] = self.activity_by_month_of_year.get(month, 0) + 1

			# yearly/weekly activity
			yyw = date.strftime('%Y-%W')
			self.activity_by_year_week[yyw] = self.activity_by_year_week.get(yyw, 0) + 1
			if self.activity_by_year_week_peak < self.activity_by_year_week[yyw]:
				self.activity_by_year_week_peak = self.activity_by_year_week[yyw]

			# author stats
			if author not in self.authors:
				self.authors[author] = {}
			# commits, note again that commits may be in any date order because of cherry-picking and patches
			if 'last_commit_stamp' not in self.authors[author]:
				self.authors[author]['last_commit_stamp'] = stamp
			if stamp > self.authors[author]['last_commit_stamp']:
				self.authors[author]['last_commit_stamp'] = stamp
			if 'first_commit_stamp' not in self.authors[author]:
				self.authors[author]['first_commit_stamp'] = stamp
			if stamp < self.authors[author]['first_commit_stamp']:
				self.authors[author]['first_commit_stamp'] = stamp

			# author of the month/year
			yymm = date.strftime('%Y-%m')
			if yymm in self.author_of_month:
				self.author_of_month[yymm][author] = self.author_of_month[yymm].get(author, 0) + 1
			else:
				self.author_of_month[yymm] = {}
				self.author_of_month[yymm][author] = 1
			self.commits_by_month[yymm] = self.commits_by_month.get(yymm, 0) + 1

			yy = date.year
			if yy in self.author_of_year:
				self.author_of_year[yy][author] = self.author_of_year[yy].get(author, 0) + 1
			else:
				self.author_of_year[yy] = {}
				self.author_of_year[yy][author] = 1
			self.commits_by_year[yy] = self.commits_by_year.get(yy, 0) + 1

			# authors: active days
			yymmdd = date.strftime('%Y-%m-%d')
			if 'last_active_day' not in self.authors[author]:
				self.authors[author]['last_active_day'] = yymmdd
				self.authors[author]['active_days'] = set([yymmdd])
			elif yymmdd != self.authors[author]['last_active_day']:
				self.authors[author]['last_active_day'] = yymmdd
				self.authors[author]['active_days'].add(yymmdd)

			# project: active days
			if yymmdd != self.last_active_day:
				self.last_active_day = yymmdd
				self.active_days.add(yymmdd)

			# timezone
			self.commits_by_timezone[timezone] = self.commits_by_timezone.get(timezone, 0) + 1

		# outputs "<stamp> <files>" for each revision
		revlines = getpipeoutput(['git rev-list --pretty=format:"%%at %%T %%an" %s' % getlogrange('HEAD'), 'grep -v ^commit']).strip().split('\n')
		lines = []
		revs_to_read = []
		time_rev_count = []
		#Look up rev in cache and take info from cache if found
		#If not append rev to list of rev to read from repo
		for revline in revlines:
			_revline = revline.split(' ')
			time, rev = _revline[:2]
			author = ' '.join(_revline[2:])
			if author in conf["excluded_authors"]:
				continue
			#if cache empty then add time and rev to list of new rev's
			#otherwise try to read needed info from cache
			if 'files_in_tree' not in self.cache.keys():
				revs_to_read.append((time,rev))
				continue
			if rev in self.cache['files_in_tree'].keys():
				lines.append('%d %d' % (int(time), self.cache['files_in_tree'][rev]))
			else:
				revs_to_read.append((time,rev))

		#Read revisions from repo
		pool = Pool(processes=conf['processes'])
		time_rev_count = pool.map(getnumoffilesfromrev, revs_to_read)
		pool.terminate()
		pool.join()

		#Update cache with new revisions and append then to general list
		for (time, rev, count) in time_rev_count:
			if 'files_in_tree' not in self.cache:
				self.cache['files_in_tree'] = {}
			self.cache['files_in_tree'][rev] = count
			lines.append('%d %d' % (int(time), count))

		self.total_commits += len(lines)
		for line in lines:
			parts = line.split(' ')
			if len(parts) != 2:
				continue
			(stamp, files) = parts[0:2]
			date = datetime.datetime.fromtimestamp(int(stamp))
			yymm = date.strftime('%Y-%m')
			try:
				self.files_by_stamp[int(stamp)] = int(files)
				self.files_by_month[yymm] = int(files)
			except ValueError:
				print('Warning: failed to parse line "%s"' % line)

		# extensions and size of files
		lines = getpipeoutput(['git ls-tree -r -l -z %s' % getcommitrange('HEAD', end_only = True)]).split('\000')
		blobs_to_read = []
		for line in lines:
			if len(line) == 0:
				continue
			parts = re.split('\s+', line, 4)
			if parts[0] == '160000' and parts[3] == '-':
				# skip submodules
				continue
			blob_id = parts[2]
			size = int(parts[3])
			fullpath = parts[4]
			exclude = False
			for path in conf["excluded_prefixes"]:
				if fullpath.startswith(path):
					exclude = True
					break

			if exclude:
				continue

			self.total_size += size
			self.total_files += 1

			filename = fullpath.split('/')[-1] # strip directories
			if filename.find('.') == -1 or filename.rfind('.') == 0:
				ext = ''
			else:
				ext = filename[(filename.rfind('.') + 1):]
			if len(ext) > conf['max_ext_length']:
				ext = ''
			if ext not in self.extensions:
				self.extensions[ext] = {'files': 0, 'lines': 0}
			self.extensions[ext]['files'] += 1
			#if cache empty then add ext and blob id to list of new blob's
			#otherwise try to read needed info from cache
			if 'lines_in_blob' not in self.cache.keys():
				blobs_to_read.append((ext,blob_id))
				continue
			if blob_id in self.cache['lines_in_blob'].keys():
				self.extensions[ext]['lines'] += self.cache['lines_in_blob'][blob_id]
			else:
				blobs_to_read.append((ext,blob_id))

		#Get info abount line count for new blob's that wasn't found in cache
		pool = Pool(processes=conf['processes'])
		ext_blob_linecount = pool.map(getnumoflinesinblob, blobs_to_read)
		pool.terminate()
		pool.join()

		#Update cache and write down info about number of number of lines
		for (ext, blob_id, linecount) in ext_blob_linecount:
			if 'lines_in_blob' not in self.cache:
				self.cache['lines_in_blob'] = {}
			self.cache['lines_in_blob'][blob_id] = linecount
			self.extensions[ext]['lines'] += self.cache['lines_in_blob'][blob_id]

		# line statistics
		# outputs:
		#  N files changed, N insertions (+), N deletions(-)
		# <stamp> <author>
		self.changes_by_date = {} # stamp -> { files, ins, del }
		self.changes_by_month = {} # yyMM -> { files, ins, del }
		self.changes_by_year = {} # yy -> { files, ins, del }
		# computation of lines of code by date is better done
		# on a linear history.
		extra = ''
		if conf['linear_linestats']:
			extra = '--first-parent -m'
		lines = getpipeoutput(['git log --shortstat %s --pretty=format:"%%at %%aN" %s' % (extra, getlogrange('HEAD'))]).split('\n')
		lines.reverse()
		files = 0; inserted = 0; deleted = 0; total_lines = 0
		author = None
		last_line = ""
		for line in lines:
			if len(line) == 0:
				continue

			# <stamp> <author>
			if re.search('files? changed', line) == None:
				pos = line.find(' ')
				if pos != -1:
					try:
						(stamp, author) = (int(line[:pos]), line[pos+1:])
						date = datetime.datetime.fromtimestamp(stamp)
						yymm = date.strftime('%Y-%m')

						if author not in conf["excluded_authors"]:
							self.changes_by_date[stamp] = { 'files': files, 'ins': inserted, 'del': deleted, 'lines': total_lines }
							self.changes_by_year[date.year] = { 
								'files': files, 
								'ins': inserted, 
								'del': deleted,
								'lines': total_lines
								}
							self.changes_by_month[yymm] = { 
								'files': files, 
								'ins': inserted, 
								'del': deleted,
								'lines': total_lines
								}

							self.lines_added_by_month[yymm] = self.lines_added_by_month.get(yymm, 0) + inserted
							self.lines_removed_by_month[yymm] = self.lines_removed_by_month.get(yymm, 0) + deleted

							yy = date.year
							self.lines_added_by_year[yy] = self.lines_added_by_year.get(yy,0) + inserted
							self.lines_removed_by_year[yy] = self.lines_removed_by_year.get(yy, 0) + deleted

							# lineactivity
							# hour
							hour = date.hour
							self.lineactivity_by_hour_of_day[hour] = self.lineactivity_by_hour_of_day.get(hour, 0) + inserted + deleted
							# most active hour?
							if self.lineactivity_by_hour_of_day[hour] > self.lineactivity_by_hour_of_day_busiest:
								self.lineactivity_by_hour_of_day_busiest = self.lineactivity_by_hour_of_day[hour]

							# day of week
							day = date.weekday()
							self.lineactivity_by_day_of_week[day] = self.lineactivity_by_day_of_week.get(day, 0) + inserted + deleted

							# domain stats
							#if domain not in self.domains:
								#self.domains[domain] = {}
							# lines
							#self.domains[domain]['lines'] = self.domains[domain].get('lines', 0) + 1

							# hour of week
							if day not in self.lineactivity_by_hour_of_week:
								self.lineactivity_by_hour_of_week[day] = {}
							self.lineactivity_by_hour_of_week[day][hour] = self.lineactivity_by_hour_of_week[day].get(hour, 0) + inserted + deleted
							# most active hour?
							if self.lineactivity_by_hour_of_week[day][hour] > self.lineactivity_by_hour_of_week_busiest:
								self.lineactivity_by_hour_of_week_busiest = self.lineactivity_by_hour_of_week[day][hour]

							# month of year
							month = date.month
							self.lineactivity_by_month_of_year[month] = self.lineactivity_by_month_of_year.get(month, 0) + inserted + deleted

							# yearly/weekly activity
							yyw = date.strftime('%Y-%W')
							self.lineactivity_by_year_week[yyw] = self.lineactivity_by_year_week.get(yyw, 0) + inserted + deleted
							if self.lineactivity_by_year_week_peak < self.lineactivity_by_year_week[yyw]:
								self.lineactivity_by_year_week_peak = self.lineactivity_by_year_week[yyw]

							files, inserted, deleted = 0, 0, 0

							numbers = getstatsummarycounts(last_line)
							if len(numbers) == 3:
								(files, inserted, deleted) = [int(el) for el in numbers]
								total_lines += inserted
								total_lines -= deleted
								self.total_lines_added += inserted
								self.total_lines_removed += deleted
							else:
								print('Warning: failed to handle line "%s"' % line)
								(files, inserted, deleted) = (0, 0, 0)
					except ValueError:
						print('Warning: unexpected line "%s"' % line)
				else:
					print('Warning: unexpected line "%s"' % line)
			else:
				last_line = line
				#self.changes_by_date[stamp] = { 'files': files, 'ins': inserted, 'del': deleted }
		self.total_lines += total_lines

		# Per-author statistics

		# defined for stamp, author only if author commited at this timestamp.

		# Similar to the above, but never use --first-parent
		# (we need to walk through every commit to know who
		# committed what, not just through mainline)
		lines = getpipeoutput(['git log --shortstat --date-order --pretty=format:"%%at %%aN" %s' % (getlogrange('HEAD'))]).split('\n')
		lines.reverse()
		files = 0; inserted = 0; deleted = 0
		author = None
		stamp = 0
		for line in lines:
			if len(line) == 0:
				continue

			# <stamp> <author>
			if re.search('files? changed', line) == None:
				pos = line.find(' ')
				if pos != -1:
					try:
						oldstamp = stamp
						(stamp, author) = (int(line[:pos]), line[pos+1:])
						date = datetime.datetime.fromtimestamp(float(stamp))
						yyMM =  date.strftime('%Y-%m')
						if author not in conf["excluded_authors"]:
							if oldstamp > stamp:
								# clock skew, keep old timestamp to avoid having ugly graph
								stamp = oldstamp
							if author not in self.authors:
								self.authors[author] = { 'lines_added' : 0, 'lines_removed' : 0, 'commits' : 0}
							self.authors[author]['commits'] = self.authors[author].get('commits', 0) + 1
							self.authors[author]['lines_added'] = self.authors[author].get('lines_added', 0) + inserted
							self.authors[author]['lines_removed'] = self.authors[author].get('lines_removed', 0) + deleted

							if stamp not in self.changes_by_date_by_author:
								self.changes_by_date_by_author[stamp] = {}
							if yyMM not in self.changes_by_month_by_author:
								self.changes_by_month_by_author[yyMM] = {}

							if author not in self.changes_by_date_by_author[stamp]:
								self.changes_by_date_by_author[stamp][author] = {}
							if author not in self.changes_by_month_by_author[yyMM]:
								self.changes_by_month_by_author[yyMM][author] = {}

							self.changes_by_date_by_author[stamp][author]['lines_added'] = self.authors[author]['lines_added']
							self.changes_by_date_by_author[stamp][author]['lines_removed'] = self.authors[author]['lines_removed']
							self.changes_by_date_by_author[stamp][author]['commits'] = self.authors[author]['commits']

							self.changes_by_month_by_author[yyMM][author]['lines_added'] = self.changes_by_month_by_author[yyMM][author].get('lines_added', 0) + self.authors[author]['lines_added']
							self.changes_by_month_by_author[yyMM][author]['lines_removed'] = self.changes_by_month_by_author[yyMM][author].get('lines_removed', 0) + self.authors[author]['lines_removed']
							self.changes_by_month_by_author[yyMM][author]['commits'] = self.changes_by_month_by_author[yyMM][author].get('commits', 0) + self.authors[author]['commits']
							files, inserted, deleted = 0, 0, 0
					except ValueError:
						print('Warning: unexpected line "%s"' % line)
				else:
					print('Warning: unexpected line "%s"' % line)
			else:
				numbers = getstatsummarycounts(line);

				if len(numbers) == 3:
					(files, inserted, deleted) = [int(el) for el in numbers]
				else:
					print('Warning: failed to handle line "%s"' % line)
					(files, inserted, deleted) = (0, 0, 0)
	
	def refine(self):
		# authors
		# name -> {place_by_commits, commits_frac, date_first, date_last, timedelta}
		self.authors_by_commits = getkeyssortedbyvaluekey(self.authors, 'commits')
		self.authors_by_commits.reverse() # most first
		for i, name in enumerate(self.authors_by_commits):
			self.authors[name]['place_by_commits'] = i + 1

		for name in self.authors.keys():
			a = self.authors[name]
			a['commits_frac'] = (100 * float(a['commits'])) / self.getTotalCommits()
			date_first = datetime.datetime.fromtimestamp(a['first_commit_stamp'])
			date_last = datetime.datetime.fromtimestamp(a['last_commit_stamp'])
			delta = date_last - date_first
			a['date_first'] = date_first.strftime('%Y-%m-%d')
			a['date_last'] = date_last.strftime('%Y-%m-%d')
			a['timedelta'] = delta
			if 'lines_added' not in a: a['lines_added'] = 0
			if 'lines_removed' not in a: a['lines_removed'] = 0
	
	def getActiveDays(self):
		return self.active_days

	def getActivityByDayOfWeek(self):
		return self.activity_by_day_of_week

	def getActivityByHourOfDay(self):
		return self.activity_by_hour_of_day
	
	def getLineActivityByDayOfWeek(self):
		return self.lineactivity_by_day_of_week

	def getLineActivityByHourOfDay(self):
		return self.lineactivity_by_hour_of_day

	def getAuthorInfo(self, author):
		return self.authors[author]
	
	def getAuthors(self, limit = None):
		res = getkeyssortedbyvaluekey(self.authors, 'commits')
		res.reverse()
		return res[:limit]
	
	def getCommitDeltaDays(self):
		return (self.last_commit_stamp / 86400 - self.first_commit_stamp / 86400) + 1

	def getDomainInfo(self, domain):
		return self.domains[domain]

	def getDomains(self):
		return self.domains.keys()
	
	def getFirstCommitDate(self):
		return datetime.datetime.fromtimestamp(self.first_commit_stamp)
	
	def getLastCommitDate(self):
		return datetime.datetime.fromtimestamp(self.last_commit_stamp)
	
	def getTags(self):
		lines = getpipeoutput(['git show-ref --tags', 'cut -d/ -f3'])
		return lines.split('\n')
	
	def getTagDate(self, tag):
		return self.revToDate('tags/' + tag)
	
	def getTotalAuthors(self):
		return self.total_authors
	
	def getTotalCommits(self):
		return self.total_commits

	def getTotalFiles(self):
		return self.total_files
	
	def getTotalLOC(self):
		return self.total_lines
	
	def getTotalLines(self):
		return self.total_lines_added + self.total_lines_removed

	def getTotalSize(self):
		return self.total_size
	
	def revToDate(self, rev):
		stamp = int(getpipeoutput(['git log --pretty=format:%%at "%s" -n 1' % rev]))
		return datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d')

class ReportCreator:
	"""Creates the actual report based on given data."""
	def __init__(self):
		pass
	
	def create(self, data, path):
		self.data = data
		self.path = path

def html_linkify(text):
	return text.lower().replace(' ', '_')

def html_header(level, text):
	name = html_linkify(text)
	return '\n<h%d id="%s"><a href="#%s">%s</a></h%d>\n\n' % (level, name, name, text, level)


class GitDataCollectorJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, set):
            return list(obj)
        if isinstance(obj, datetime.timedelta):
            return str(obj)
        if isinstance(obj, GitDataCollector):
            return obj.__dict__
        # Let the base class default method raise the TypeError
        return json.JSONEncoder.default(self, obj)

class JSONReportCreator(ReportCreator):
    def create(self, data, filename):
        f = open(filename, 'w')
        json.dump(data, f, indent=True,
                cls=GitDataCollectorJSONEncoder)
        f.close()
class HTMLReportCreator(ReportCreator):
	def create(self, data, path):
		ReportCreator.create(self, data, path)
		self.title = data.projectname

		# copy static files. Looks in the binary directory, ../share/gitstats and /usr/share/gitstats
		binarypath = os.path.dirname(os.path.abspath(__file__))
		secondarypath = os.path.join(binarypath, '..', 'share', 'gitstats')
		basedirs = [binarypath, secondarypath, '/usr/share/gitstats']
		for file in (conf['style'], 'sortable.js', 'arrow-up.gif', 'arrow-down.gif', 'arrow-none.gif', 'tailwind.json', 'html.py'):
			for base in basedirs:
				src = base + '/' + file
				if os.path.exists(src):
					shutil.copyfile(src, path + '/' + file)
					break
			else:
				print('Warning: "%s" not found, so not copied (searched: %s)' % (file, basedirs))
		##
		# index.html
		# General
		format = '%Y-%m-%d %H:%M:%S'

		general_html = html.HTML(path=f'{path}/index.html', title=f"{data.projectname}'S STATS", version= getversion())

		general_html.add('<div class="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-6">')
		general_html.tilesItemStat(title='Project name', info=data.projectname)
		general_html.tilesItemStat(title='Generated', info=datetime.datetime.now().strftime(format))
		general_html.tilesItemStat(title='Report Period', info=f'{data.getFirstCommitDate().strftime(format)} to {data.getLastCommitDate().strftime(format)}')
		general_html.add('</div>')

		
		general_html.add('<div class="grid grid-cols-1 gap-4 md:grid-cols-2 md:gap-6 xl:grid-cols-4 2xl:gap-7.5">')
		general_html.cardItemStat(title='Branches', count=data.total_branches)
		general_html.cardItemStat(title='Tags', count=data.total_tags)
		general_html.cardItemStat(title='Age', count=f'{data.getCommitDeltaDays():.1f} days')
		general_html.cardItemStat(title='Active days', count=f'{len(data.getActiveDays())}', stat=f'{(100.0 * len(data.getActiveDays()) / data.getCommitDeltaDays()):3.2f}%', arrow='up')
		general_html.cardItemStat(title='Total files', count=data.getTotalFiles())
		general_html.cardItemStat(title='Total LOC', count=data.getTotalLOC())
		general_html.cardItemStat(title='Total lines added', count=data.total_lines_added, stat=f'{((data.total_lines_added/data.getTotalLOC())*100):.2f}%', arrow='up')
		general_html.cardItemStat(title='Total lines removed', count=data.total_lines_removed, stat=f'{((data.total_lines_removed/data.getTotalLOC())*100):.2f}%', arrow='up')
		general_html.cardItemStat(title='Total commits', count=data.getTotalCommits(), stat=f'{(float(data.getTotalCommits()) / len(data.getActiveDays())):.1f}', arrow='up')
		general_html.cardItemStat(title='Authors', count=data.getTotalAuthors(), stat=f'{((1.0 * data.getTotalCommits()) / data.getTotalAuthors()):.1f}', arrow='up')
		general_html.add('</div>')

		# general_content.append('<div><div class="card-body"><dl>')
		# general_content.append('<dt>Project name</dt><dd>%s (%s branches, %s tags)</dd>' % (data.projectname, data.total_branches, data.total_tags))
		# general_content.append('<dt>Generated</dt><dd>%s (in %d seconds)</dd>' % (datetime.datetime.now().strftime(format), time.time() - data.getStampCreated()))
		# general_content.append('<dt>Generator</dt><dd><a href="http://gitstats.sourceforge.net/">GitStats</a> (version %s), %s, %s</dd>' % (getversion(), getgitversion(), getgnuplotversion()))
		# general_content.append('<dt>Report Period</dt><dd>%s to %s</dd>' % (data.getFirstCommitDate().strftime(format), data.getLastCommitDate().strftime(format)))
		# general_content.append('<dt>Age</dt><dd>%d days, %d active days (%3.2f%%)</dd>' % (data.getCommitDeltaDays(), len(data.getActiveDays()), (100.0 * len(data.getActiveDays()) / data.getCommitDeltaDays())))
		# general_content.append('<dt>Total Files</dt><dd>%s</dd>' % data.getTotalFiles())
		# general_content.append('<dt>Total Lines of Code</dt><dd>%s (%d added, %d removed)</dd>' % (data.getTotalLOC(), data.total_lines_added, data.total_lines_removed))
		# general_content.append('<dt>Total Commits</dt><dd>%s (average %.1f commits per active day, %.1f per all days)</dd>' % (data.getTotalCommits(), float(data.getTotalCommits()) / len(data.getActiveDays()), float(data.getTotalCommits()) / data.getCommitDeltaDays()))
		# general_content.append('<dt>Authors</dt><dd>%s (average %.1f commits per author)</dd>' % (data.getTotalAuthors(), (1.0 * data.getTotalCommits()) / data.getTotalAuthors()))
		# general_content.append('</dl></div></div>')

		general_html.create()


		chart_default_config = json.load(open('chart.json'))

		###
		# activity.html
		# Activity
		totalcommits = data.getTotalCommits()

		activity_html = html.HTML(path=f'{path}/activity.html', title='Activity', version= getversion())

		activity_html.add('<div class="grid grid-cols-12 gap-4 md:gap-6 2xl:gap-7.5">')

		# Last 30 days
		# Last 12 months

		# Activity :: Weekly activity
		WEEKS = 32
		# generate weeks to show (previous N weeks from now)
		now = datetime.datetime.now()
		deltaweek = datetime.timedelta(7)
		weeks = []
		stampcur = now
		for i in range(0, WEEKS):
			weeks.insert(0, stampcur.strftime('%Y-%W'))
			stampcur -= deltaweek
		
		activity_per_weekly_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Percentage", "color": "#779EF1", "data": []},
		]
		for i in range(0, WEEKS):
			commits = data.activity_by_year_week[weeks[i]] if weeks[i] in data.activity_by_year_week else 0
			activity_per_weekly_series[0]['data'].append({"x": f'{WEEKS-i}', "y": commits})
			activity_per_weekly_series[1]['data'].append({"x": f'{WEEKS-i}', "y": f'{((100.0 * commits) / totalcommits):.2f}'})
		
		activity_per_weekly_config = {
			**chart_default_config,
			"series": activity_per_weekly_series
		}

		activity_html.addChart(activity_per_weekly_config, name='chartWeeklyActivity', title=f'Weekly activity <span class="text-xs font-medium">Last {WEEKS} weeks</span>', className="")
		

		# Activity :: Hour of Day
		hour_of_day = data.getActivityByHourOfDay()

		activity_per_hours_day_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Percentage", "color": "#779EF1", "data": []},
		]

		for i in range(0, 24):
			commits = hour_of_day[i] if i in hour_of_day else 0
			activity_per_hours_day_series[0]["data"].append({"x": f'{i}', "y": commits})
			activity_per_hours_day_series[1]["data"].append({"x": f'{i}', "y": f'{((100.0 * commits) / totalcommits):.2f}'})

		activity_per_hours_day_config = {
			**chart_default_config, 
			"series": activity_per_hours_day_series
		}
		
		activity_html.addChart(activity_per_hours_day_config, name='chartHourOfDay', title='Hour of Day', className="")


		# Activity :: Day of Week
		day_of_week = data.getActivityByDayOfWeek()

		activity_per_day_week_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Percentage", "color": "#779EF1", "data": []},
		]

		for d in range(0, 7):
			commits = day_of_week[d] if d in day_of_week else 0
			activity_per_day_week_series[0]["data"].append({"x": WEEKDAYS[d], "y": commits})
			activity_per_day_week_series[1]["data"].append({"x": WEEKDAYS[d], "y": f'{((100.0 * commits) / totalcommits):.2f}'})

		activity_per_day_week_config = {
			**chart_default_config,
			"series": activity_per_day_week_series
		}
		
		activity_html.addChart(activity_per_day_week_config, name='chartDayofWeek', title='Day of Week', className="xl:col-span-4")

		# Activity :: Hour of Week
		activity_hour_of_week_series = []

		for weekday in range(0, 7):
			activity_hour_of_week_series.append({"name": WEEKDAYS[weekday], "data": []})
			for hour in range(0, 24):
				try:
					commits = data.activity_by_hour_of_week[weekday][hour]
				except KeyError:
					commits = 0
				
				activity_hour_of_week_series[weekday]["data"].append({"x": f'{hour}', "y": commits})

		activity_hour_of_week_series.reverse()

		activity_hour_of_week_config = {
			"series": activity_hour_of_week_series,
			"chart": {**chart_default_config["chart"], "type": 'heatmap'},
      		"dataLabels": chart_default_config["dataLabels"],
			"colors": ["#3C50E0"],
			"xaxis": chart_default_config["xaxis"],
			"yaxis": chart_default_config["yaxis"],
		}

		activity_html.addChart(activity_hour_of_week_config, name='chartHourOfWeek', title='Hour of Week', className="xl:col-span-8")
	
		# Activity :: Month of Year
		activity_per_month_of_year_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Percentage", "color": "#779EF1", "data": []},
		]
		for mm in range(1, 13):
			commits = data.activity_by_month_of_year[mm] if mm in data.activity_by_month_of_year else 0
			activity_per_month_of_year_series[0]["data"].append({"x": f'{mm}', "y": commits, "percentage": (100.0 * commits) /totalcommits})
			activity_per_month_of_year_series[1]["data"].append({"x": f'{mm}', "y": f'{((100.0 * commits) /totalcommits):.2f}'})

		activity_per_month_of_year_config = {
			**chart_default_config,
			"series": activity_per_month_of_year_series
		}

		activity_html.addChart(activity_per_month_of_year_config, name='chartMonthOfYear', title='Month of Year', className="xl:col-span-5")


		# Activity :: Commits by year/month
		activity_per_year_month_serie = []
		for yymm in sorted(data.commits_by_month.keys()):
			activity_per_year_month_serie.append({"x": f'{yymm}', "y": data.commits_by_month.get(yymm,0), "lines_added": data.lines_added_by_month.get(yymm,0), "lines_removed": data.lines_removed_by_month.get(yymm,0), "percentage": (100.0 * data.commits_by_month.get(yymm,0)) /totalcommits})

		activity_per_year_month_config = {
			**chart_default_config,
			"series": [{
			"name": "Commits",
			"color": "#1A56DB",
			"data": activity_per_year_month_serie}],
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**chart_default_config["xaxis"]["labels"] , 
					"show" : False
					}}}

		activity_html.addChart(activity_per_year_month_config, name='chartCommitsByYearMonth', title='Commits by year/month', className="xl:col-span-7")


		# Activity :: Commits by year
		activity_by_year_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Lines Added", "color": "#23961B","data": []},
			{"name": "Lines Removed", "color": "#DB1A1A","data": []},
			{"name": "Percentage", "color": "#779EF1","data": []}]
		
		for yy in sorted(data.commits_by_year.keys()):
			activity_by_year_series[0]["data"].append({"x": f'{yy}', "y": data.commits_by_year.get(yy,0)})
			activity_by_year_series[1]["data"].append({"x": f'{yy}', "y": data.lines_added_by_year.get(yy,0)})
			activity_by_year_series[2]["data"].append({"x": f'{yy}', "y": data.lines_removed_by_year.get(yy,0)})
			activity_by_year_series[3]["data"].append({"x": f'{yy}', "y": f'{((100.0 * data.commits_by_year.get(yy,0)) /totalcommits):.2f}'})

		activity_by_year_config = {
			**chart_default_config,
			"series": activity_by_year_series
			}

		activity_html.addChart(activity_by_year_config, name='chartCommitsByYear', title='Commits by Year', className="xl:col-span-6")

		# Activity :: Commits by timezone
		activity_by_timezone_series = [
			{"name": "Commits", "color": "#1A56DB", "data": []},
			{"name": "Percentage", "color": "#779EF1", "data": []},
		]
		max_commits_on_tz = max(data.commits_by_timezone.values())
		for i in sorted(data.commits_by_timezone.keys(), key = lambda n : int(n)):
			commits = data.commits_by_timezone.get(i, 0)
			activity_by_timezone_series[0]["data"].append({"x": f'{i}', "y": commits})
			activity_by_timezone_series[1]["data"].append({"x": f'{i}', "y": f'{((100.0 * commits) /totalcommits):.2f}'})

		activity_by_timezone_config = {
			**chart_default_config,
			"series": activity_by_timezone_series
		}

		activity_html.addChart(activity_by_timezone_config, name='chartCommitsByTimezone', title='Commits by Timezone', className="xl:col-span-6")

		activity_html.add('</div>')

		activity_html.create()

		###
		# authors.html
		# Authors
		authors_html = html.HTML(path=f'{path}/authors.html', title='Authors', version= getversion())
		authors_html.add('<div class="grid grid-cols-12 gap-4 md:gap-6 2xl:gap-7.5">')
		

		# Authors :: List of authors
		list_authors_content = []

		list_authors_content.append('<div><div class="card-body"><table class="authors sortable" id="authors">')
		list_authors_content.append('<tr><th>Author</th><th>Commits (%)</th><th>+ lines</th><th>- lines</th><th>First commit</th><th>Last commit</th><th class="unsortable">Age</th><th>Active days</th><th># by commits</th></tr>')
		for author in data.getAuthors(conf['max_authors']):
			info = data.getAuthorInfo(author)
			list_authors_content.append('<tr><td>%s</td><td>%d (%.2f%%)</td><td>%d</td><td>%d</td><td>%s</td><td>%s</td><td>%s</td><td>%d</td><td>%d</td></tr>' % (author, info['commits'], info['commits_frac'], info['lines_added'], info['lines_removed'], info['date_first'], info['date_last'], info['timedelta'], len(info['active_days']), info['place_by_commits']))
		list_authors_content.append('</table></div></div>')

		allauthors = data.getAuthors()
		if len(allauthors) > conf['max_authors']:
			rest = allauthors[conf['max_authors']:]
			list_authors_content.append('<p class="moreauthors">These didn\'t make it to the top: %s</p>' % ', '.join(rest))
		
		authors_html.addCard(list_authors_content, title='List of Authors')

		# Authors :: Commits
		author_disclaimer = ''
		max_authors = conf['max_authors']
		if len(allauthors) > max_authors:
			author_disclaimer =f'<span class="text-xs font-medium">Only top {max_authors} authors shown</span>'

		lines_by_authors = {} # cumulated added lines by
		# lines_removed_by_authors = {}
		# author. to save memory,
		# changes_by_date_by_author[stamp][author] is defined
		# only at points where author commits.
		# lines_by_authors allows us to generate all the
		# points in the .dat file.

		# Don't rely on getAuthors to give the same order each
		# time. Be robust and keep the list in a variable.
		commits_by_authors = {} # cumulated added lines by

		colors = [
		"#4B0082",
		"#2E8B57",
		"#7B68EE",
		"#BA55D3",
		"#DB7093",
		"#FFD700",
		"#006400",
		"#008080",
		"#191970",
		"#0000CD",
		"#CD5C5C",
		"#FAFAD2",
		"#7FFF00",
		"#9966CC",
		"#D2B48C",
		"#000080",
		"#AFEEEE",
		"#8B008B",
		"#008000",
		"#6A5ACD"]

		authors_cumulated_lines_added_series = {}
		# authors_cumulated_lines_removed_series = {}
		authors_commits_series = {}

		self.authors_to_plot = data.getAuthors(conf['max_authors'])
		for idx, author in enumerate(self.authors_to_plot):
			lines_by_authors[author] = 0
			# lines_removed_by_authors[author] = 0
			commits_by_authors[author] = 0

			authors_cumulated_lines_added_series[author]= {"name": author, "color": colors[idx], "data": []}
			# authors_cumulated_lines_removed_series[author]= {"name": author, "color": colors[idx], "data": []}
			authors_commits_series[author]= {"name": author, "color": colors[idx], "data": []}

		# for stamp in sorted(data.changes_by_date_by_author.keys()):
		# 	for author in self.authors_to_plot:
		# 		if author in data.changes_by_date_by_author[stamp].keys():
		# 			lines_by_authors[author] = data.changes_by_date_by_author[stamp][author]['lines_added']
		# 			commits_by_authors[author] = data.changes_by_date_by_author[stamp][author]['commits']
		# 		# authors_cumulated_commits_series[author]['data'].append({"x": stamp, "y": lines_by_authors[author]})
				
		# 		authors_cumulated_commits_series[author]['data'].append(lines_by_authors[author])
		# 		authors_commits_series[author]['data'].append(commits_by_authors[author])

		for yyMM in sorted(data.changes_by_month_by_author.keys()):
			for author in self.authors_to_plot:
				if author in data.changes_by_month_by_author[yyMM].keys():
					lines_by_authors[author] = lines_by_authors[author] + data.changes_by_month_by_author[yyMM][author]['lines_added']
					# lines_removed_by_authors[author] = lines_removed_by_authors[author] + data.changes_by_month_by_author[yyMM][author]['lines_removed']
					commits_by_authors[author] = commits_by_authors[author] + data.changes_by_month_by_author[yyMM][author]['commits']
				
				# authors_cumulated_commits_series[author]['data'].append(lines_by_authors[author])
				authors_cumulated_lines_added_series[author]['data'].append({"x": yyMM, "y": lines_by_authors[author]})
				# authors_cumulated_lines_removed_series[author]['data'].append({"x": yyMM, "y": lines_removed_by_authors[author]})
				authors_commits_series[author]['data'].append({"x": yyMM, "y": commits_by_authors[author]})
				# authors_commits_series[author]['data'].append(commits_by_authors[author])

		# Authors :: Cumulated added LoC per author
		authors_cumulated_commits_config = {
			**chart_default_config,
			"chart": {**chart_default_config["chart"], "type": 'line'},
			"series": list(authors_cumulated_lines_added_series.values()),
			"markers": {"size": 0,"hover": {"sizeOffset": 6}},
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**chart_default_config["xaxis"]["labels"] , 
					"show" : False
					}}
		}

		authors_html.addChart(authors_cumulated_commits_config, name='chartCumulatedAddedLoCAuthor', title=f'Cumulated Added LoC per Author {author_disclaimer}', className="xl:col-span-6")

		# Authors :: Cumulated removed LoC per author
		# authors_cumulated_removed_loc_config = {
		# 	**chart_default_config,
		# 	"chart": {**chart_default_config["chart"], "type": 'line'},
		# 	"series": list(authors_cumulated_lines_removed_series.values()),
		# 	"markers": {"size": 0,"hover": {"sizeOffset": 6}},
		# 	"xaxis": {
		# 		**chart_default_config["xaxis"], 
		# 		"labels": {
		# 			**chart_default_config["xaxis"]["labels"] , 
		# 			"show" : False
		# 			}}
		# }

		# authors_html.addChart(authors_cumulated_removed_loc_config, name='chartCumulatedRemovedLoCAuthor', title=f'Cumulated removed LoC per Author {author_disclaimer}', className="xl:col-span-6")


		# Authors :: Commits per Author
		authors_commits_config = {
			**chart_default_config,
			"chart": {**chart_default_config["chart"], "type": 'line'},
			"series": list(authors_commits_series.values()),
			"markers": {"size": 0,"hover": {"sizeOffset": 6}},
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**chart_default_config["xaxis"]["labels"] , 
					"show" : False
					}}
		}

		authors_html.addChart(authors_commits_config, name='chartCommitsPerAuthor', title=f'Commits per Author {author_disclaimer}', className="xl:col-span-6")


		# Authors :: Author of Month
		author_of_month_content = []
		author_of_month_content.append('<table class="sortable" id="aom">')
		author_of_month_content.append('<tr><th>Month</th><th>Author</th><th>Commits (%%)</th><th class="unsortable">Next top %d</th><th>Number of authors</th></tr>' % conf['authors_top'])
		for yymm in reversed(sorted(data.author_of_month.keys())):
			authordict = data.author_of_month[yymm]
			authors = getkeyssortedbyvalues(authordict)
			authors.reverse()
			commits = data.author_of_month[yymm][authors[0]]
			next = ', '.join(authors[1:conf['authors_top']+1])
			author_of_month_content.append('<tr><td>%s</td><td>%s</td><td>%d (%.2f%% of %d)</td><td>%s</td><td>%d</td></tr>' % (yymm, authors[0], commits, (100.0 * commits) / data.commits_by_month[yymm], data.commits_by_month[yymm], next, len(authors)))

		author_of_month_content.append('</table>')

		authors_html.addCard(author_of_month_content, title='Author of Month')

		# Authors :: Author of Year
		author_of_year_content = []
		author_of_year_content.append('<table class="sortable" id="aoy"><tr><th>Year</th><th>Author</th><th>Commits (%%)</th><th class="unsortable">Next top %d</th><th>Number of authors</th></tr>' % conf['authors_top'])
		for yy in reversed(sorted(data.author_of_year.keys())):
			authordict = data.author_of_year[yy]
			authors = getkeyssortedbyvalues(authordict)
			authors.reverse()
			commits = data.author_of_year[yy][authors[0]]
			next = ', '.join(authors[1:conf['authors_top']+1])
			author_of_year_content.append('<tr><td>%s</td><td>%s</td><td>%d (%.2f%% of %d)</td><td>%s</td><td>%d</td></tr>' % (yy, authors[0], commits, (100.0 * commits) / data.commits_by_year[yy], data.commits_by_year[yy], next, len(authors)))
		author_of_year_content.append('</table>')

		authors_html.addCard(author_of_year_content, title='Author of Year', className="xl:col-span-6")

		# Authors :: Domains
		domains_by_commits = getkeyssortedbyvaluekey(data.domains, 'commits')
		domains_by_commits.reverse() # most first

		authors_commits_by_domains_series = [{
			"name": "Commits",
			"color": "#1A56DB",
			"data": []
		},{
			"name": "Percentage",
			"color": "#8FB0F6",
			"data": []
		}]
		n = 0
		for domain in domains_by_commits:
			if n == conf['max_domains']:
				break
			commits = 0
			n += 1
			info = data.getDomainInfo(domain)
			authors_commits_by_domains_series[0]['data'].append({"x": domain, "y": info['commits']})
			p = (100.0 * info['commits'] / totalcommits)
			authors_commits_by_domains_series[1]['data'].append({"x": domain, "y": f'{p:.2f}'})

		authors_commits_by_domains_config = {
			**chart_default_config,
			"series": authors_commits_by_domains_series,
		}

		authors_html.addChart(authors_commits_by_domains_config, name='chartCommitsbyDomains', title='Commits by Domains', className="xl:col-span-6")

		authors_html.add('</div>')

		authors_html.create()

		###
		# files.html
		# Files
		files_html = html.HTML(path=f'{path}/files.html', title='Files', version= getversion())

		files_html.add('<div class="grid grid-cols-1 gap-4 md:grid-cols-2 md:gap-6 xl:grid-cols-4 2xl:gap-7.5 mb-6">')
		files_html.cardItemStat(title='Total files', count=data.getTotalFiles())
		files_html.cardItemStat(title='Total LoC', count=data.getTotalLOC())
		try:
			files_html.cardItemStat(title='Average file size', count=f'{(float(data.getTotalSize()) / data.getTotalFiles()):2f} bytes')
		except ZeroDivisionError:
			pass
		files_html.add('</div>')

		files_html.add('<div class="grid grid-cols-12 gap-4 md:gap-6 2xl:gap-7.5">')

		# Files :: File count by date
		files_by_month_series = {"name": 'Files', "color": "#3C50E0", "data": []}
		# # use set to get rid of duplicate/unnecessary entries
		# files_by_date = set()
		# for stamp in sorted(data.files_by_stamp.keys()):
		# 	files_by_date.add('%s %d' % (datetime.datetime.fromtimestamp(stamp).strftime('%Y-%m-%d'), data.files_by_stamp[stamp]))

		for yyMM in sorted(data.files_by_month.keys()):
			files_by_month_series["data"].append({"x": yyMM, "y": data.files_by_month[yyMM]})

		files_by_month_config = {
			**chart_default_config,
			"chart": {**chart_default_config["chart"], "type": 'line'},
			"series": [files_by_month_series],
			"markers": {"size": 0,"hover": {"sizeOffset": 6}},
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**chart_default_config["xaxis"]["labels"] , 
					"show" : False
					}}
		}

		files_html.addChart(files_by_month_config, name='chartFilesByMonth', title='File count by month', className="xl:col-span-12")


		#files_content.append('<h2>Average file size by date</h2>')

		# Files :: Extensions
		files_extensions_series = {"name": 'Extensions', "color": "#3C50E0", "data": []}
		files_extensions_content = []
		files_extensions_content.append('<table class="sortable" id="ext"><tr><th>Extension</th><th>Files (%)</th><th>Lines (%)</th><th>Lines/file</th></tr>')
		for ext in sorted(data.extensions.keys()):
			files = data.extensions[ext]['files']
			lines = data.extensions[ext]['lines']
			try:
				loc_percentage = (100.0 * lines) / data.getTotalLOC()
			except ZeroDivisionError:
				loc_percentage = 0
			files_extensions_content.append('<tr><td>%s</td><td>%d (%.2f%%)</td><td>%d (%.2f%%)</td><td>%d</td></tr>' % (ext, files, (100.0 * files) / data.getTotalFiles(), lines, loc_percentage, lines / files))
			files_extensions_series["data"].append({"x": ext, "y": files})
		files_extensions_content.append('</table>')

		files_extensions_config = {
			"chart": {**chart_default_config["chart"], "type": 'treemap'},
			"series": [files_extensions_series],
		}

		files_html.addChart(files_extensions_config, name='chartFilesByExtensions', title='Extensions treemap', className="xl:col-span-12")

		files_html.addCard(files_extensions_content, title='Extensions', className="xl:col-span-4")


		files_html.add('</div>')

		files_html.create()

		###
		# lines.html
		# Lines
		lines_content=[]
		lines_html = html.HTML(path=f'{path}/lines.html', title='Lines', version= getversion())

		lines_html.add('<div class="grid grid-cols-1 gap-4 md:grid-cols-2 md:gap-6 xl:grid-cols-4 2xl:gap-7.5 mb-6">')
		lines_html.cardItemStat(title='Total LoC', count=data.getTotalLOC())
		lines_html.add('</div>')

		lines_html.add('<div class="grid grid-cols-12 gap-4 md:gap-6 2xl:gap-7.5">')


		lines_by_year_series = {"name": 'Lines', "color": "#3C50E0", "data": []}

		for year in sorted(data.changes_by_year.keys()):
			lines_by_year_series["data"].append({"x": year, "y": data.changes_by_year[year]['lines']})


		lines_by_year_config = {
			**chart_default_config,
			"chart": {**chart_default_config["chart"], "type": 'line'},
			"series": [lines_by_year_series],
			"markers": {"size": 0,"hover": {"sizeOffset": 6}},
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**chart_default_config["xaxis"]["labels"] , 
					"show" : False
					}}
		}

		lines_html.addChart(lines_by_year_config, name='chartLinesOfCodeByYear', title='Lines of Code by Year', className="xl:col-span-6")

		lines_by_month_series = {"name": 'Lines', "color": "#3C50E0", "data": []}

		for yyMM in sorted(data.changes_by_month.keys()):
			lines_by_month_series["data"].append({"x": yyMM, "y": data.changes_by_month[yyMM]['lines']})

		lines_by_month_config = {
			**lines_by_year_config,
			"series": [lines_by_month_series],
		}

		lines_html.addChart(lines_by_month_config, name='chartLinesByMonth', title='Lines of Code by Month', className="xl:col-span-6")




		# Lines :: Weekly activity
		WEEKS = 32
		# lines_content.append(html_header(2, 'Weekly activity'))
		# lines_content.append('<p>Last %d weeks</p>' % WEEKS)

		# generate weeks to show (previous N weeks from now)
		now = datetime.datetime.now()
		deltaweek = datetime.timedelta(7)
		weeks = []
		stampcur = now
		for i in range(0, WEEKS):
			weeks.insert(0, stampcur.strftime('%Y-%W'))
			stampcur -= deltaweek

		lines_per_weekly_serie = {"name": "LoC", "color": "#1A56DB", "data": []}
		for i in range(0, WEEKS):
			lines = data.lineactivity_by_year_week[weeks[i]] if weeks[i] in data.lineactivity_by_year_week else 0
			lines_per_weekly_serie['data'].append({"x": f'{WEEKS-i}', "y": lines})
		
		lines_per_weekly_config = {
			**chart_default_config,
			"series": [lines_per_weekly_serie]
		}

		lines_html.addChart(lines_per_weekly_config, name='chartLinesWeeklyActivity', title=f'Weekly activity <span class="text-xs font-medium">Last {WEEKS} weeks</span>', className="")		

		# Lines :: Hour of Day
		hour_of_day = data.getLineActivityByHourOfDay()

		lines_per_hours_day_serie = {"name": "LoC", "color": "#1A56DB", "data": []}

		for i in range(0, 24):
			lines = hour_of_day[i] if i in hour_of_day else 0
			lines_per_hours_day_serie["data"].append({"x": f'{i}', "y": lines})

		lines_per_hours_day_config = {
			**chart_default_config, 
			"series": [lines_per_hours_day_serie]
		}
		
		lines_html.addChart(lines_per_hours_day_config, name='chartLinesHourOfDay', title='Hour of Day', className="")

		# Lines :: Day of Week
		day_of_week = data.getLineActivityByDayOfWeek()

		lines_per_day_week_serie= {"name": "LoC", "color": "#1A56DB", "data": []}

		for d in range(0, 7):
			lines = day_of_week[d] if d in day_of_week else 0
			lines_per_day_week_serie["data"].append({"x": WEEKDAYS[d], "y": lines})

		lines_per_day_week_config = {
			**chart_default_config,
			"series": [lines_per_day_week_serie]
		}
		
		lines_html.addChart(lines_per_day_week_config, name='chartLinesDayofWeek', title='Day of Week', className="xl:col-span-4")


		# Lines :: Hour of Week
		lines_hour_of_week_series = []

		for weekday in range(0, 7):
			lines_hour_of_week_series.append({"name": WEEKDAYS[weekday], "data": []})
			for hour in range(0, 24):
				try:
					lines = data.lineactivity_by_hour_of_week[weekday][hour]
				except KeyError:
					lines = 0
				
				lines_hour_of_week_series[weekday]["data"].append({"x": f'{hour}', "y": lines})

		lines_hour_of_week_series.reverse()

		lines_hour_of_week_config = {
			"series": lines_hour_of_week_series,
			"chart": {**chart_default_config["chart"], "type": 'heatmap'},
      		"dataLabels": chart_default_config["dataLabels"],
			"colors": ["#3C50E0"],
			"xaxis": chart_default_config["xaxis"],
			"yaxis": chart_default_config["yaxis"],
		}

		lines_html.addChart(lines_hour_of_week_config, name='chartLinesHourOfWeek', title='Hour of Week', className="xl:col-span-8")
	


		# Lines :: Month of Year
		lines_per_month_of_year_series= {"name": "LoC", "color": "#1A56DB", "data": []}
		
		for mm in range(1, 13):
			lines = data.lineactivity_by_month_of_year[mm] if mm in data.lineactivity_by_month_of_year else 0
			lines_per_month_of_year_series["data"].append({"x": f'{mm}', "y": lines, "percentage": (100.0 * lines) /data.getTotalLines()})

		lines_per_month_of_year_config = {
			**chart_default_config,
			"series": [lines_per_month_of_year_series]
		}

		lines_html.addChart(lines_per_month_of_year_config, name='chartLinesMonthOfYear', title='Month of Year', className="xl:col-span-5")


		# Lines :: Lines by year/month
		lines_per_year_month_serie = []
		
		for yymm in sorted(data.commits_by_month.keys()):
			lines_per_year_month_serie.append({"x": f'{yymm}', "y": data.lines_added_by_month.get(yymm, 0) + data.lines_removed_by_month.get(yymm, 0)})

		lines_per_year_month_config = {
			**chart_default_config,
			"series": [{
			"name": "Commits",
			"color": "#1A56DB",
			"data": lines_per_year_month_serie}],
			"xaxis": {
				**chart_default_config["xaxis"], 
				"labels": {
					**activity_per_year_month_config["xaxis"]["labels"] , 
					"show" : False
					}}}

		lines_html.addChart(lines_per_year_month_config, name='chartCommitsByYearMonth', title='Lines by year/month', className="xl:col-span-7")


		# Lines :: Lines by year
		lines_by_year_serie= {"name": "Lines", "color": "#1A56DB", "data": []}

		for yy in sorted(data.commits_by_year.keys()):
			lines_by_year_serie["data"].append({"x": f'{yy}', "y": data.lines_added_by_year.get(yy,0) - data.lines_removed_by_year.get(yy,0)})

		lines_by_year_config = {
			**chart_default_config,
			"series": [lines_by_year_serie]
			}

		lines_html.addChart(lines_by_year_config, name='chartLinesByYear', title='Lines by Year', className="xl:col-span-6")


		lines_html.add('</div>')

		lines_html.create(lines_content)

		###
		# tags.html
		tags_html = html.HTML(path=f'{path}/tags.html', title='Tags', version= getversion())

		tags_html.add('<div class="grid grid-cols-1 gap-4 md:grid-cols-2 md:gap-6 xl:grid-cols-4 2xl:gap-7.5 mb-6">')
		tags_html.cardItemStat(title='Total tags', count=len(data.tags))
		tags_html.cardItemStat(title='Average commits per tag', count=f'{(1.0 * data.getTotalCommits() / len(data.tags)):.2f}')
		tags_html.add('</div>')

		tags_table_content = ['<table class="tags">']
		tags_table_content.append('<tr><th>Name</th><th>Date</th><th>Commits</th><th>Authors</th></tr>')
		# sort the tags by date desc
		tags_sorted_by_date_desc = [el[1] for el in reversed(sorted([(el[1]['date'], el[0]) for el in list(data.tags.items())]))]
		for tag in tags_sorted_by_date_desc:
			authorinfo = []
			self.authors_by_commits = getkeyssortedbyvalues(data.tags[tag]['authors'])
			for i in reversed(self.authors_by_commits):
				authorinfo.append('%s (%d)' % (i, data.tags[tag]['authors'][i]))
			tags_table_content.append('<tr><td>%s</td><td>%s</td><td>%d</td><td>%s</td></tr>' % (tag, data.tags[tag]['date'], data.tags[tag]['commits'], ', '.join(authorinfo)))
		tags_table_content.append('</table>')

		tags_html.addCard(tags_table_content, title='Tags information')

		tags_html.create()
	
	
def usage():
	text = """
Usage: gitstats [options] <gitpath..> <outputpath>

Options:
-c key=value     Override configuration value

Default config values:
%s

Please see the manual page for more details.
""" % conf
	print(text)

class GitStats:
	def run(self, args_orig):
		optlist, args = getopt.getopt(args_orig, 'hc:', ["help"])
		for o,v in optlist:
			if o == '-c':
				key, value = v.split('=', 1)
				if key not in conf:
					raise KeyError('no such key "%s" in config' % key)
				if isinstance(conf[key], int):
					conf[key] = int(value)
				elif isinstance(conf[key], list):
					conf[key].append(value)
				else:
					conf[key] = value
			elif o in ('-h', '--help'):
				usage()
				sys.exit()

		if len(args) < 2:
			usage()
			sys.exit(0)

		outputpath = os.path.abspath(args[-1])
		rundir = os.getcwd()

		try:
			os.makedirs(outputpath)
		except OSError:
			pass
		if not os.path.isdir(outputpath):
			print('FATAL: Output path is not a directory or does not exist')
			sys.exit(1)

		print('Output path: %s' % outputpath)
		cachefile = os.path.join(outputpath, 'gitstats.cache')

		data = GitDataCollector()
		data.loadCache(cachefile)

		for gitpath in args[0:-1]:
			print('Git path: %s' % gitpath)

			prevdir = os.getcwd()
			os.chdir(gitpath)

			print('Collecting data...')
			data.collect(gitpath)

			os.chdir(prevdir)

		print('Refining data...')
		data.saveCache(cachefile)
		data.refine()

		os.chdir(rundir)

		print('Generating HTML report...')
		report = HTMLReportCreator()
		report.create(data, outputpath)

		print('Generating JSON report...')
		report = JSONReportCreator()
		report.create(data, os.path.join(outputpath, JSONFILE))

		time_end = time.time()
		exectime_internal = time_end - time_start
		print('Execution time %.5f secs, %.5f secs (%.2f %%) in external commands)' % (exectime_internal, exectime_external, (100.0 * exectime_external) / exectime_internal))
		if sys.stdin.isatty():
			print('You may now run:')
			print()
			print('   sensible-browser \'%s\'' % os.path.join(outputpath, 'index.html').replace("'", "'\\''"))
			print('   sensible-notepad \'%s\'' % os.path.join(outputpath, JSONFILE).replace("'", "'\\''"))
			print()

if __name__=='__main__':
	g = GitStats()
	g.run(sys.argv[1:])


# https://github.com/TailAdmin/tailadmin-free-tailwind-dashboard-template/tree/main
# https://codepen.io/Zsena/pen/ZEMaaoX?editors=1010
# https://sebastiandedeyne.com/non-reactive-data-in-alpine-js/